{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = [[2,3],[4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data = torch.tensor(some_data)\n",
    "some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_arr = np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41996386, 0.52845479, 0.26980113, 0.04505521],\n",
       "       [0.14900383, 0.99298271, 0.82227998, 0.58211668],\n",
       "       [0.08985049, 0.5556848 , 0.76893802, 0.56238482]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4200, 0.5285, 0.2698, 0.0451],\n",
       "        [0.1490, 0.9930, 0.8223, 0.5821],\n",
       "        [0.0899, 0.5557, 0.7689, 0.5624]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(numpy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4200, 0.5285, 0.2698, 0.0451],\n",
       "        [0.1490, 0.9930, 0.8223, 0.5821],\n",
       "        [0.0899, 0.5557, 0.7689, 0.5624]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(numpy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor can be at cpu or gpu depending on where you want your computation on \n",
    "my_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_tensor.to(\"cuda\") # won't work since i have no gpu\n",
    "# otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3378, 0.4855, 0.3059],\n",
       "        [0.2478, 0.9531, 0.4088, 0.0489],\n",
       "        [0.6590, 0.9333, 0.7587, 0.9620]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3378, 0.4855],\n",
       "        [0.9531, 0.4088],\n",
       "        [0.9333, 0.7587]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2299, 0.1141, 0.2357, 0.0936],\n",
       "        [0.0614, 0.9084, 0.1671, 0.0024],\n",
       "        [0.4343, 0.8711, 0.5757, 0.9254]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.mul(my_tensor) # element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2299, 0.1141, 0.2357, 0.0936],\n",
       "        [0.0614, 0.9084, 0.1671, 0.0024],\n",
       "        [0.4343, 0.8711, 0.5757, 0.9254]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor * my_tensor # element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6734, 0.6543, 1.2939],\n",
       "        [0.6543, 1.1393, 1.4101],\n",
       "        [1.2939, 1.4101, 2.8064]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.matmul(my_tensor.T) # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6734, 0.6543, 1.2939],\n",
       "        [0.6543, 1.1393, 1.4101],\n",
       "        [1.2939, 1.4101, 2.8064]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(my_tensor,my_tensor.T) # another way to do matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3863, 2.2243, 1.6531, 1.3168])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.sum(axis=0) # sum of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6087, 1.6586, 3.3130])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.sum(axis=1) # sum of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9620)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0489)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3378, 0.4855, 0.3059, 0.4795, 0.3378, 0.4855, 0.3059],\n",
       "        [0.2478, 0.9531, 0.4088, 0.0489, 0.2478, 0.9531, 0.4088, 0.0489],\n",
       "        [0.6590, 0.9333, 0.7587, 0.9620, 0.6590, 0.9333, 0.7587, 0.9620]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([my_tensor,my_tensor],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =torch.tensor([[2,3],[4,9]], dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(axis=0) # along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(axis=1) # along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(dim=0) # along columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(dim=1) # along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack([x,x],dim=0) # along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 3],\n",
      "         [4, 9]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [4, 9]]], dtype=torch.int8) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 3],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 9],\n",
      "         [4, 9]]], dtype=torch.int8) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack([x,x],dim=1) # along columns\n",
    "print(z,z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3378, 0.4855, 0.3059],\n",
       "        [0.2478, 0.9531, 0.4088, 0.0489],\n",
       "        [0.6590, 0.9333, 0.7587, 0.9620]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2692, 0.2336, 0.2708, 0.2263],\n",
       "        [0.1992, 0.4034, 0.2341, 0.1633],\n",
       "        [0.2095, 0.2756, 0.2314, 0.2836]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(my_tensor,dim=1) # along rows take softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1553, 0.0618, 0.7889,  ..., 0.3665, 0.3679, 0.5554],\n",
       "          [0.7732, 0.1350, 0.9570,  ..., 0.3114, 0.8158, 0.5015],\n",
       "          [0.2236, 0.7300, 0.8065,  ..., 0.0616, 0.6281, 0.8064],\n",
       "          ...,\n",
       "          [0.9102, 0.2992, 0.6020,  ..., 0.9822, 0.6906, 0.3926],\n",
       "          [0.5598, 0.6864, 0.4845,  ..., 0.3341, 0.9633, 0.1551],\n",
       "          [0.6749, 0.5319, 0.8764,  ..., 0.5804, 0.8119, 0.0344]],\n",
       "\n",
       "         [[0.9201, 0.9207, 0.7241,  ..., 0.8181, 0.3830, 0.0667],\n",
       "          [0.9342, 0.5942, 0.6564,  ..., 0.0670, 0.7618, 0.3860],\n",
       "          [0.7946, 0.2718, 0.3918,  ..., 0.1158, 0.8076, 0.0183],\n",
       "          ...,\n",
       "          [0.0279, 0.6458, 0.4937,  ..., 0.2697, 0.5673, 0.1509],\n",
       "          [0.4887, 0.4984, 0.0437,  ..., 0.4916, 0.6920, 0.1009],\n",
       "          [0.2746, 0.3278, 0.9769,  ..., 0.8822, 0.8621, 0.2401]],\n",
       "\n",
       "         [[0.1055, 0.7951, 0.7398,  ..., 0.9106, 0.4798, 0.4283],\n",
       "          [0.9223, 0.4609, 0.4871,  ..., 0.4942, 0.5835, 0.2203],\n",
       "          [0.4882, 0.9838, 0.5442,  ..., 0.3076, 0.6920, 0.9032],\n",
       "          ...,\n",
       "          [0.0757, 0.0574, 0.1691,  ..., 0.5078, 0.2744, 0.9987],\n",
       "          [0.4892, 0.3236, 0.1403,  ..., 0.1592, 0.0269, 0.7873],\n",
       "          [0.7777, 0.7815, 0.6015,  ..., 0.5894, 0.6773, 0.4531]]],\n",
       "\n",
       "\n",
       "        [[[0.7454, 0.5222, 0.2367,  ..., 0.5824, 0.9947, 0.2969],\n",
       "          [0.2333, 0.0416, 0.8096,  ..., 0.5448, 0.2997, 0.6039],\n",
       "          [0.5987, 0.6378, 0.4667,  ..., 0.3677, 0.8728, 0.7264],\n",
       "          ...,\n",
       "          [0.8667, 0.3299, 0.3800,  ..., 0.7756, 0.6556, 0.4343],\n",
       "          [0.0143, 0.7978, 0.9523,  ..., 0.5975, 0.5802, 0.4184],\n",
       "          [0.7777, 0.1868, 0.3402,  ..., 0.4448, 0.7051, 0.5276]],\n",
       "\n",
       "         [[0.7148, 0.5018, 0.9144,  ..., 0.1990, 0.2683, 0.5734],\n",
       "          [0.5557, 0.4613, 0.5553,  ..., 0.6721, 0.2443, 0.1233],\n",
       "          [0.8852, 0.5767, 0.4452,  ..., 0.3086, 0.7767, 0.7676],\n",
       "          ...,\n",
       "          [0.2740, 0.2210, 0.6500,  ..., 0.4556, 0.0117, 0.3391],\n",
       "          [0.7238, 0.5448, 0.7793,  ..., 0.4179, 0.2888, 0.7971],\n",
       "          [0.2873, 0.6387, 0.7073,  ..., 0.2430, 0.6514, 0.6743]],\n",
       "\n",
       "         [[0.0842, 0.7067, 0.6708,  ..., 0.9981, 0.3505, 0.5901],\n",
       "          [0.4474, 0.4168, 0.0591,  ..., 0.9908, 0.2807, 0.3389],\n",
       "          [0.5691, 0.8138, 0.9642,  ..., 0.0231, 0.8930, 0.0189],\n",
       "          ...,\n",
       "          [0.8467, 0.1013, 0.0415,  ..., 0.3654, 0.6392, 0.7942],\n",
       "          [0.8519, 0.0310, 0.2211,  ..., 0.5404, 0.1330, 0.6977],\n",
       "          [0.6957, 0.3950, 0.4248,  ..., 0.1719, 0.7621, 0.0880]]],\n",
       "\n",
       "\n",
       "        [[[0.3275, 0.3127, 0.8606,  ..., 0.4299, 0.6814, 0.8710],\n",
       "          [0.6927, 0.8754, 0.4645,  ..., 0.5858, 0.2405, 0.8900],\n",
       "          [0.5537, 0.8678, 0.9516,  ..., 0.0591, 0.1580, 0.2411],\n",
       "          ...,\n",
       "          [0.5175, 0.2440, 0.7794,  ..., 0.3849, 0.3823, 0.1023],\n",
       "          [0.3310, 0.1213, 0.5357,  ..., 0.3432, 0.3545, 0.3834],\n",
       "          [0.1697, 0.8363, 0.5664,  ..., 0.8528, 0.1461, 0.7284]],\n",
       "\n",
       "         [[0.4470, 0.9636, 0.8350,  ..., 0.6446, 0.4275, 0.0200],\n",
       "          [0.4441, 0.1246, 0.4246,  ..., 0.4501, 0.0274, 0.0955],\n",
       "          [0.4423, 0.0711, 0.1868,  ..., 0.4970, 0.7377, 0.0452],\n",
       "          ...,\n",
       "          [0.7594, 0.0941, 0.1667,  ..., 0.3414, 0.1408, 0.0914],\n",
       "          [0.0478, 0.5929, 0.2205,  ..., 0.1488, 0.2476, 0.9453],\n",
       "          [0.4416, 0.0328, 0.7494,  ..., 0.1782, 0.6220, 0.8354]],\n",
       "\n",
       "         [[0.2384, 0.6895, 0.4981,  ..., 0.7046, 0.3820, 0.0614],\n",
       "          [0.9554, 0.5651, 0.2360,  ..., 0.9183, 0.8464, 0.0854],\n",
       "          [0.8916, 0.8231, 0.2696,  ..., 0.3325, 0.3113, 0.1807],\n",
       "          ...,\n",
       "          [0.2463, 0.6538, 0.8497,  ..., 0.7565, 0.7047, 0.2746],\n",
       "          [0.6650, 0.6073, 0.9957,  ..., 0.7474, 0.2256, 0.2208],\n",
       "          [0.2461, 0.0999, 0.0920,  ..., 0.8862, 0.6866, 0.9960]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.5580, 0.4595, 0.7622,  ..., 0.0978, 0.7767, 0.1614],\n",
       "          [0.6749, 0.4782, 0.5244,  ..., 0.9085, 0.6312, 0.7282],\n",
       "          [0.4301, 0.2357, 0.0577,  ..., 0.2333, 0.2623, 0.6623],\n",
       "          ...,\n",
       "          [0.8879, 0.0910, 0.1539,  ..., 0.2703, 0.5345, 0.4689],\n",
       "          [0.9711, 0.3094, 0.1831,  ..., 0.4903, 0.6281, 0.6069],\n",
       "          [0.4097, 0.0308, 0.1758,  ..., 0.5579, 0.5274, 0.1136]],\n",
       "\n",
       "         [[0.2543, 0.1509, 0.7388,  ..., 0.4246, 0.8904, 0.3461],\n",
       "          [0.2931, 0.0899, 0.6066,  ..., 0.4706, 0.8007, 0.5070],\n",
       "          [0.4673, 0.9295, 0.5258,  ..., 0.9029, 0.4946, 0.1850],\n",
       "          ...,\n",
       "          [0.1125, 0.1740, 0.1670,  ..., 0.9740, 0.4693, 0.2873],\n",
       "          [0.5604, 0.5659, 0.5662,  ..., 0.2112, 0.2770, 0.6878],\n",
       "          [0.0559, 0.9213, 0.4203,  ..., 0.2501, 0.6377, 0.8566]],\n",
       "\n",
       "         [[0.4022, 0.5802, 0.9068,  ..., 0.6280, 0.8422, 0.5254],\n",
       "          [0.4911, 0.9759, 0.7083,  ..., 0.9631, 0.4389, 0.3351],\n",
       "          [0.6910, 0.3928, 0.9993,  ..., 0.2250, 0.6544, 0.7553],\n",
       "          ...,\n",
       "          [0.7282, 0.0212, 0.7387,  ..., 0.6139, 0.6513, 0.2521],\n",
       "          [0.8188, 0.7968, 0.0025,  ..., 0.2491, 0.5099, 0.6907],\n",
       "          [0.2368, 0.2096, 0.3440,  ..., 0.0487, 0.1866, 0.8588]]],\n",
       "\n",
       "\n",
       "        [[[0.4375, 0.1114, 0.4006,  ..., 0.2329, 0.7996, 0.9564],\n",
       "          [0.6978, 0.9834, 0.5908,  ..., 0.1193, 0.9248, 0.9311],\n",
       "          [0.7877, 0.0938, 0.1678,  ..., 0.9451, 0.7033, 0.4907],\n",
       "          ...,\n",
       "          [0.4772, 0.7290, 0.8796,  ..., 0.8051, 0.8465, 0.1240],\n",
       "          [0.6671, 0.4008, 0.4962,  ..., 0.9502, 0.6505, 0.9469],\n",
       "          [0.6922, 0.6191, 0.9593,  ..., 0.9505, 0.8644, 0.8787]],\n",
       "\n",
       "         [[0.1234, 0.3500, 0.3213,  ..., 0.9740, 0.5405, 0.2367],\n",
       "          [0.6414, 0.4339, 0.3200,  ..., 0.4769, 0.2229, 0.7724],\n",
       "          [0.0036, 0.2517, 0.8131,  ..., 0.7667, 0.7442, 0.8967],\n",
       "          ...,\n",
       "          [0.6741, 0.8932, 0.4996,  ..., 0.4463, 0.2834, 0.1409],\n",
       "          [0.0143, 0.9280, 0.8130,  ..., 0.3378, 0.4624, 0.8039],\n",
       "          [0.9491, 0.2142, 0.7491,  ..., 0.8798, 0.1205, 0.5170]],\n",
       "\n",
       "         [[0.0063, 0.0577, 0.3934,  ..., 0.1035, 0.1659, 0.7745],\n",
       "          [0.5321, 0.8357, 0.4409,  ..., 0.5945, 0.4349, 0.0259],\n",
       "          [0.3560, 0.4549, 0.0874,  ..., 0.4074, 0.2172, 0.0305],\n",
       "          ...,\n",
       "          [0.8289, 0.2016, 0.8404,  ..., 0.0833, 0.0609, 0.5738],\n",
       "          [0.3465, 0.9973, 0.5445,  ..., 0.1051, 0.2642, 0.0307],\n",
       "          [0.0501, 0.9398, 0.5626,  ..., 0.2669, 0.1994, 0.7939]]],\n",
       "\n",
       "\n",
       "        [[[0.1434, 0.6158, 0.9480,  ..., 0.5809, 0.2137, 0.0160],\n",
       "          [0.6707, 0.7198, 0.8914,  ..., 0.1961, 0.6323, 0.8072],\n",
       "          [0.2358, 0.3868, 0.5447,  ..., 0.3715, 0.8748, 0.6029],\n",
       "          ...,\n",
       "          [0.4331, 0.6689, 0.4772,  ..., 0.9591, 0.0354, 0.5717],\n",
       "          [0.7603, 0.3343, 0.8121,  ..., 0.4563, 0.5523, 0.0937],\n",
       "          [0.0489, 0.2218, 0.6284,  ..., 0.0529, 0.2699, 0.8424]],\n",
       "\n",
       "         [[0.6842, 0.0276, 0.8031,  ..., 0.9381, 0.4137, 0.0704],\n",
       "          [0.2042, 0.7079, 0.1778,  ..., 0.2398, 0.0907, 0.1251],\n",
       "          [0.6030, 0.2549, 0.2087,  ..., 0.9072, 0.1949, 0.5737],\n",
       "          ...,\n",
       "          [0.1544, 0.5244, 0.0286,  ..., 0.0962, 0.5464, 0.1174],\n",
       "          [0.6169, 0.7248, 0.9640,  ..., 0.1061, 0.1360, 0.6540],\n",
       "          [0.0246, 0.6213, 0.3191,  ..., 0.1196, 0.9776, 0.6420]],\n",
       "\n",
       "         [[0.0719, 0.5075, 0.7460,  ..., 0.5048, 0.0026, 0.7950],\n",
       "          [0.3531, 0.5378, 0.9300,  ..., 0.1885, 0.5085, 0.1570],\n",
       "          [0.3708, 0.5370, 0.0081,  ..., 0.7535, 0.4663, 0.4227],\n",
       "          ...,\n",
       "          [0.1624, 0.4949, 0.3718,  ..., 0.6953, 0.3850, 0.1253],\n",
       "          [0.3659, 0.4994, 0.6111,  ..., 0.2471, 0.0599, 0.6183],\n",
       "          [0.7316, 0.0145, 0.4372,  ..., 0.1813, 0.2553, 0.7825]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10,3,128,128) # batch size, channels, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3378, 0.4855, 0.3059],\n",
       "        [0.2478, 0.9531, 0.4088, 0.0489],\n",
       "        [0.6590, 0.9333, 0.7587, 0.9620]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4795, 0.3378, 0.4855, 0.3059],\n",
       "        [0.2478, 0.8000, 0.4088, 0.2000],\n",
       "        [0.6590, 0.8000, 0.7587, 0.8000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.clip(0.2,0.8) # all values below 0.2 will be set to 0.2 and all values above 0.8 will be set to 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47948724, 0.33783215, 0.48553532, 0.30589283],\n",
       "       [0.24775344, 0.9531116 , 0.40883827, 0.04890925],\n",
       "       [0.65901744, 0.9333352 , 0.7587221 , 0.9619527 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.cpu().detach().numpy() # bring tensor to cpu and convert to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    " # autograd: automatic differention engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([5.], requires_grad=True)\n",
    "b = torch.tensor([6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = a**3 - b**2 \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dy/da = 3a^2 # 75\n",
    "# dy/db = 2b   # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(10,1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0045],\n",
       "        [-2.5019],\n",
       "        [-0.9910],\n",
       "        [ 1.1298],\n",
       "        [-0.7724],\n",
       "        [-1.3997],\n",
       "        [-0.0159],\n",
       "        [ 0.4500],\n",
       "        [ 0.6930],\n",
       "        [-0.3522]], requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8840], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(b,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3848, 0.0714, 0.2591, 0.8440, 0.9483, 0.7928, 0.6574, 0.1923, 0.1564,\n",
       "         0.2222]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1,10) # 1 sample with 10 features\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7153]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = torch.matmul(x,W) + b\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7153]], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 1-output # demo loss function\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both output and loss has grad_fn associated\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3848],\n",
       "        [-0.0714],\n",
       "        [-0.2591],\n",
       "        [-0.8440],\n",
       "        [-0.9483],\n",
       "        [-0.7928],\n",
       "        [-0.6574],\n",
       "        [-0.1923],\n",
       "        [-0.1564],\n",
       "        [-0.2222]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with torch.no_grad(): # this temporarily disables gradient calculation for all variables in this context\n",
    "  W = W - learning_rate * W.grad.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0083],\n",
       "        [-2.5012],\n",
       "        [-0.9884],\n",
       "        [ 1.1382],\n",
       "        [-0.7629],\n",
       "        [-1.3917],\n",
       "        [-0.0093],\n",
       "        [ 0.4520],\n",
       "        [ 0.6946],\n",
       "        [-0.3500]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import  make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(torch.utils.data.Dataset): # inherits from Dataset class from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "  def __init__(self, data, targets):\n",
    "    self.data = data\n",
    "    self.targets = targets\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0] # assuming data is numpy array\n",
    "  def __getitem__(self, index):\n",
    "    if index < 0 or index >= self.data.shape[0]:\n",
    "      raise IndexError(\"Index out of range\")\n",
    "    current_sample = self.data[index,:]\n",
    "    current_target = self.targets[index]\n",
    "    return {\n",
    "      \"sample\": torch.tensor(current_sample, dtype=torch.float),\n",
    "      \"target\": torch.tensor(current_target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mmake_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_informative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_redundant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_repeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_clusters_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mflip_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_sep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhypercube\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generate a random n-class classification problem.\n",
      "\n",
      "This initially creates clusters of points normally distributed (std=1)\n",
      "about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "class. It introduces interdependence between these features and adds\n",
      "various types of further noise to the data.\n",
      "\n",
      "Without shuffling, ``X`` horizontally stacks features in the following\n",
      "order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "linear combinations of the informative features, followed by ``n_repeated``\n",
      "duplicates, drawn randomly with replacement from the informative and\n",
      "redundant features. The remaining features are filled with random noise.\n",
      "Thus, without shuffling, all useful features are contained in the columns\n",
      "``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "\n",
      "For an example of usage, see\n",
      ":ref:`sphx_glr_auto_examples_datasets_plot_random_dataset.py`.\n",
      "\n",
      "Read more in the :ref:`User Guide <sample_generators>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_samples : int, default=100\n",
      "    The number of samples.\n",
      "\n",
      "n_features : int, default=20\n",
      "    The total number of features. These comprise ``n_informative``\n",
      "    informative features, ``n_redundant`` redundant features,\n",
      "    ``n_repeated`` duplicated features and\n",
      "    ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "    drawn at random.\n",
      "\n",
      "n_informative : int, default=2\n",
      "    The number of informative features. Each class is composed of a number\n",
      "    of gaussian clusters each located around the vertices of a hypercube\n",
      "    in a subspace of dimension ``n_informative``. For each cluster,\n",
      "    informative features are drawn independently from  N(0, 1) and then\n",
      "    randomly linearly combined within each cluster in order to add\n",
      "    covariance. The clusters are then placed on the vertices of the\n",
      "    hypercube.\n",
      "\n",
      "n_redundant : int, default=2\n",
      "    The number of redundant features. These features are generated as\n",
      "    random linear combinations of the informative features.\n",
      "\n",
      "n_repeated : int, default=0\n",
      "    The number of duplicated features, drawn randomly from the informative\n",
      "    and the redundant features.\n",
      "\n",
      "n_classes : int, default=2\n",
      "    The number of classes (or labels) of the classification problem.\n",
      "\n",
      "n_clusters_per_class : int, default=2\n",
      "    The number of clusters per class.\n",
      "\n",
      "weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "    The proportions of samples assigned to each class. If None, then\n",
      "    classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "    then the last class weight is automatically inferred.\n",
      "    More than ``n_samples`` samples may be returned if the sum of\n",
      "    ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "    not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "\n",
      "flip_y : float, default=0.01\n",
      "    The fraction of samples whose class is assigned randomly. Larger\n",
      "    values introduce noise in the labels and make the classification\n",
      "    task harder. Note that the default setting flip_y > 0 might lead\n",
      "    to less than ``n_classes`` in y in some cases.\n",
      "\n",
      "class_sep : float, default=1.0\n",
      "    The factor multiplying the hypercube size.  Larger values spread\n",
      "    out the clusters/classes and make the classification task easier.\n",
      "\n",
      "hypercube : bool, default=True\n",
      "    If True, the clusters are put on the vertices of a hypercube. If\n",
      "    False, the clusters are put on the vertices of a random polytope.\n",
      "\n",
      "shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "    Shift features by the specified value. If None, then features\n",
      "    are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "\n",
      "scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "    Multiply features by the specified value. If None, then features\n",
      "    are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "    happens after shifting.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Shuffle the samples and the features.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Determines random number generation for dataset creation. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "X : ndarray of shape (n_samples, n_features)\n",
      "    The generated samples.\n",
      "\n",
      "y : ndarray of shape (n_samples,)\n",
      "    The integer labels for class membership of each sample.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "make_blobs : Simplified variant.\n",
      "make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "the \"Madelon\" dataset.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "       selection benchmark\", 2003.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import make_classification\n",
      ">>> X, y = make_classification(random_state=42)\n",
      ">>> X.shape\n",
      "(100, 20)\n",
      ">>> y.shape\n",
      "(100,)\n",
      ">>> list(y[:5])\n",
      "[0, 0, 1, 1, 0]\n",
      "\u001b[0;31mFile:\u001b[0m      ~/pjct/self-py/self-py/lib/python3.10/site-packages/sklearn/datasets/_samples_generator.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02790105, -0.52432248,  1.15248637, ...,  0.45009305,\n",
       "         0.56704123, -1.3710777 ],\n",
       "       [ 0.50790132, -2.13456256, -0.16669463, ...,  1.19902107,\n",
       "        -1.57414366,  1.93129148],\n",
       "       [-0.47060167,  0.22475079,  0.62785342, ...,  0.07825731,\n",
       "         1.13545144, -0.78057703],\n",
       "       ...,\n",
       "       [-2.63100236, -0.02015831,  0.61231505, ...,  0.19952068,\n",
       "         0.53569975, -0.70356895],\n",
       "       [-0.77504255,  0.81828413, -1.8603931 , ..., -0.36425529,\n",
       "        -0.23972905, -0.53888846],\n",
       "       [-0.22830364,  1.2098013 , -0.49653036, ..., -0.31174962,\n",
       "         0.18577874,  0.78874329]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data = data, targets = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([ 0.0279, -0.5243,  1.1525,  1.4186, -0.0330,  1.5555, -1.0803,  1.1962,\n",
       "          1.4822,  0.5500, -1.0762,  1.0808, -0.1887, -1.4103, -1.0189, -1.1896,\n",
       "          1.4552,  0.4501,  0.5670, -1.3711]),\n",
       " 'target': tensor(0)}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0279, -0.5243,  1.1525,  1.4186, -0.0330,  1.5555, -1.0803,  1.1962,\n",
       "         1.4822,  0.5500, -1.0762,  1.0808, -0.1887, -1.4103, -1.0189, -1.1896,\n",
       "         1.4552,  0.4501,  0.5670, -1.3711])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0][\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set for simple NLP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification/reg problems \n",
    "class CustomDataset:\n",
    "  def __init__(self, data, targets, tokenizer):\n",
    "    self.data = data \n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, index):\n",
    "    text = self.data[index]\n",
    "    input_ids = self.tokenizer(text)\n",
    "    # input_ids are tokens, it can be of any length, so use padding for consistency\n",
    "    # padding\n",
    "    target = self.targets[index]\n",
    "    return {\"text\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            # \"attention_mask\": torch.tensor(attention_mask, dtype=torch.float),\n",
    "            \"target\": torch.tensor(target)}\n",
    "    \n",
    "# modify the code as per the requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for simple image/vision problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "  def __init__(self,image_paths, targets, augmentations):\n",
    "    self.image_paths = image_paths\n",
    "    self.targets = targets\n",
    "    self.augmentations = augmentations\n",
    "  def __len__(self):\n",
    "    return len(self.image_paths) # TODO: what to do for multiclass problem, when data is in each class folder\n",
    "    # return len(self.targets) # TODO: is it better?\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    if index < 0 or index >= len(self.targets):\n",
    "      raise IndexError(\"Index out of range\")\n",
    "    target = self.targets[index]\n",
    "    image = cv2.imread(self.image_paths[index]) # cv2 reads image in BGR format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    # read mask image if you have it\n",
    "    augmented = self.augmentations(image=image, mask = mask) # TODO: is it good practise to do augmentations in get item?\n",
    "    image = augmented[\"image\"]\n",
    "    # mask = augmented[\"mask\"]\n",
    "    \n",
    "    # pytorch expects the image to be in channel X height X width format\n",
    "    # if image is grayscale (2d array), add a channel dimension: tensor.unsqueeze(0)\n",
    "  \n",
    "    image = np.transpose(image, (2, 0, 1)).astype(np.float32) # (index = 2 means channel, index = 0 means height, index = 1 means width)\n",
    "    return {\n",
    "      \"image\": torch.tensor(image),\n",
    "      \"target\": torch.tensor(target)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader: load the data in batches to pass that in nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "  def __init__(self, data, targets):\n",
    "    self.data = data\n",
    "    self.targets = targets\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0] # assuming data is numpy array\n",
    "  def __getitem__(self, index):\n",
    "    if index < 0 or index >= self.data.shape[0]:\n",
    "      raise IndexError(\"Index out of range\")\n",
    "    current_sample = self.data[index,:]\n",
    "    current_target = self.targets[index]\n",
    "    return {\n",
    "      \"x\": torch.tensor(current_sample, dtype=torch.float),\n",
    "      \"y\": torch.tensor(current_target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)\n",
    "dataset = CustomDataset(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      "        ``True``.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[0;31mFile:\u001b[0m           ~/pjct/self-py/self-py/lib/python3.10/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 4, num_workers=2) # num_workers = no. of cpus\n",
    "# TODO: check on collate_fn, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "  print(data[\"x\"].shape)\n",
    "  print(data[\"y\"].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "  for data in train_loader:\n",
    "    x = data[\"x\"]\n",
    "    y = data[\"y\"]\n",
    "    # outputs = model(x,y) \n",
    "    # loss = ....\n",
    "    # loss.backward() \n",
    "    # .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "  def __init__(self, data, targets):\n",
    "    self.data = data\n",
    "    self.targets = targets\n",
    "  def __len__(self):\n",
    "    return self.data.shape[0] # assuming data is numpy array\n",
    "  def __getitem__(self, index):\n",
    "    if index < 0 or index >= self.data.shape[0]:\n",
    "      raise IndexError(\"Index out of range\")\n",
    "    current_sample = self.data[index,:]\n",
    "    current_target = self.targets[index]\n",
    "    return {\n",
    "      \"x\": torch.tensor(current_sample, dtype=torch.float),\n",
    "      \"y\": torch.tensor(current_target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.2, stratify=targets)\n",
    "# stratify = targets balances the splitting of class data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 4, num_workers=2) \n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 4, num_workers=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 features, 800 samples\n",
    "W = torch.randn(20,1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "model = lambda x, W, b: torch.matmul(x, W )+b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for debugging purpose\n",
    "# for data in train_loader:\n",
    "#   ytrain = data[\"y\"]\n",
    "#   xtrain = data[\"x\"]\n",
    "#   print(ytrain.shape)\n",
    "#   print(ytrain)\n",
    "#   print(\"\\n\\n\")\n",
    "#   print(ytrain.view(-1))\n",
    "#   print(\"\\n\\n\")\n",
    "#   output = model(xtrain, W, b)\n",
    "#   print(output.shape)\n",
    "#   print(output)\n",
    "#   print(\"\\n\\n\")\n",
    "#   print(output.view(-1))\n",
    "#   break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    xtest = data[\"x\"]\n",
    "    ytest = data[\"y\"]\n",
    "    output = model(xtest, W, b) # we already have updated W and b\n",
    "    outputs.append(output)\n",
    "    labels.append(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6666)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(torch.cat(labels).view(-1),torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.2243585909157995\n",
      "1 2.733622312322259\n",
      "2 1.2703756904229522\n",
      "3 0.6319175428152084\n",
      "4 0.34590297657065094\n",
      "5 0.2155058334954083\n",
      "6 0.15531855349894613\n",
      "7 0.1272759734466672\n",
      "8 0.11410790178226307\n",
      "9 0.1078808254795149\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for epoch in range(10):\n",
    "  epoch_loss = 0\n",
    "  counter = 0\n",
    "  for data in train_loader:\n",
    "    xtrain = data[\"x\"]\n",
    "    ytrain = data[\"y\"]\n",
    "    if W.grad is not None:\n",
    "      W.grad.zero_()\n",
    "      b.grad.zero_()\n",
    "    \n",
    "    output = model(xtrain, W, b)\n",
    "    loss = torch.mean((output.view(-1)-ytrain.view(-1))**2)\n",
    "    epoch_loss += loss.item() \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      W = W - learning_rate * W.grad\n",
    "      b = b - learning_rate * b.grad\n",
    "    \n",
    "   \n",
    "    W.requires_grad = True\n",
    "    b.requires_grad = True\n",
    "    counter += 1\n",
    "  \n",
    "  print(epoch, epoch_loss/counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "  for data in test_loader:\n",
    "    xtest = data[\"x\"]\n",
    "    ytest = data[\"y\"]\n",
    "    output = model(xtest, W, b) # we already have updated W and b\n",
    "    outputs.append(output)\n",
    "    labels.append(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.5618],\n",
       "         [0.5673],\n",
       "         [0.2364],\n",
       "         [0.5202]]),\n",
       " tensor([[0.6996],\n",
       "         [0.2214],\n",
       "         [0.1111],\n",
       "         [0.0438]]),\n",
       " tensor([[ 0.5301],\n",
       "         [ 0.9552],\n",
       "         [-0.2258],\n",
       "         [ 0.1616]]),\n",
       " tensor([[0.5515],\n",
       "         [0.2680],\n",
       "         [0.6203],\n",
       "         [0.3364]]),\n",
       " tensor([[0.7252],\n",
       "         [0.4925],\n",
       "         [1.1024],\n",
       "         [0.1418]]),\n",
       " tensor([[0.3567],\n",
       "         [0.9198],\n",
       "         [0.3579],\n",
       "         [0.8766]]),\n",
       " tensor([[0.6352],\n",
       "         [0.1582],\n",
       "         [0.6269],\n",
       "         [0.0196]]),\n",
       " tensor([[0.4243],\n",
       "         [0.1705],\n",
       "         [0.1947],\n",
       "         [0.0018]]),\n",
       " tensor([[0.4520],\n",
       "         [0.5331],\n",
       "         [0.5158],\n",
       "         [1.1775]]),\n",
       " tensor([[ 1.1416],\n",
       "         [-0.1528],\n",
       "         [ 0.0923],\n",
       "         [ 0.0014]]),\n",
       " tensor([[0.6262],\n",
       "         [0.2142],\n",
       "         [0.1590],\n",
       "         [0.1705]]),\n",
       " tensor([[0.1231],\n",
       "         [0.8428],\n",
       "         [0.5341],\n",
       "         [0.6478]]),\n",
       " tensor([[0.0874],\n",
       "         [0.4911],\n",
       "         [0.5980],\n",
       "         [0.8361]]),\n",
       " tensor([[0.1318],\n",
       "         [0.1105],\n",
       "         [0.2389],\n",
       "         [0.9441]]),\n",
       " tensor([[0.3398],\n",
       "         [0.2077],\n",
       "         [0.9131],\n",
       "         [0.5038]]),\n",
       " tensor([[0.1477],\n",
       "         [0.7317],\n",
       "         [0.1121],\n",
       "         [0.0614]]),\n",
       " tensor([[ 0.0153],\n",
       "         [ 0.6722],\n",
       "         [-0.0968],\n",
       "         [ 0.7098]]),\n",
       " tensor([[0.3707],\n",
       "         [0.5306],\n",
       "         [0.0213],\n",
       "         [0.4905]]),\n",
       " tensor([[ 0.3150],\n",
       "         [ 0.6587],\n",
       "         [-0.0101],\n",
       "         [ 0.9294]]),\n",
       " tensor([[0.3487],\n",
       "         [0.8737],\n",
       "         [0.3860],\n",
       "         [0.0820]]),\n",
       " tensor([[ 0.5999],\n",
       "         [ 0.4574],\n",
       "         [-0.0917],\n",
       "         [ 0.7023]]),\n",
       " tensor([[0.4628],\n",
       "         [1.0334],\n",
       "         [1.3326],\n",
       "         [0.9559]]),\n",
       " tensor([[0.8922],\n",
       "         [0.4600],\n",
       "         [0.5729],\n",
       "         [0.7317]]),\n",
       " tensor([[ 1.3882],\n",
       "         [ 0.9514],\n",
       "         [-0.1433],\n",
       "         [ 0.6863]]),\n",
       " tensor([[-0.0730],\n",
       "         [ 0.8480],\n",
       "         [ 0.2085],\n",
       "         [ 0.8043]]),\n",
       " tensor([[ 0.6907],\n",
       "         [-0.2383],\n",
       "         [ 0.3714],\n",
       "         [ 0.8061]]),\n",
       " tensor([[0.9452],\n",
       "         [1.0809],\n",
       "         [0.0131],\n",
       "         [1.2189]]),\n",
       " tensor([[0.7588],\n",
       "         [0.9282],\n",
       "         [0.8057],\n",
       "         [0.4393]]),\n",
       " tensor([[0.6067],\n",
       "         [0.9693],\n",
       "         [0.8621],\n",
       "         [0.6080]]),\n",
       " tensor([[1.0041],\n",
       "         [0.0162],\n",
       "         [0.6282],\n",
       "         [0.3103]]),\n",
       " tensor([[ 0.3680],\n",
       "         [ 0.1584],\n",
       "         [-0.0082],\n",
       "         [ 0.5436]]),\n",
       " tensor([[1.0039],\n",
       "         [0.8872],\n",
       "         [0.4266],\n",
       "         [0.5248]]),\n",
       " tensor([[0.0411],\n",
       "         [0.2039],\n",
       "         [0.6599],\n",
       "         [1.0208]]),\n",
       " tensor([[-0.1205],\n",
       "         [ 0.7596],\n",
       "         [-0.0675],\n",
       "         [ 0.4644]]),\n",
       " tensor([[0.9868],\n",
       "         [0.6241],\n",
       "         [0.6983],\n",
       "         [1.1664]]),\n",
       " tensor([[1.0884],\n",
       "         [0.3528],\n",
       "         [0.9693],\n",
       "         [0.5214]]),\n",
       " tensor([[1.5379],\n",
       "         [0.2452],\n",
       "         [0.1478],\n",
       "         [0.2222]]),\n",
       " tensor([[0.5987],\n",
       "         [0.3152],\n",
       "         [0.7177],\n",
       "         [0.1432]]),\n",
       " tensor([[-0.0277],\n",
       "         [ 0.7967],\n",
       "         [ 0.3663],\n",
       "         [ 0.0762]]),\n",
       " tensor([[0.0900],\n",
       "         [0.8476],\n",
       "         [0.6271],\n",
       "         [0.1362]]),\n",
       " tensor([[0.0936],\n",
       "         [0.1812],\n",
       "         [0.3196],\n",
       "         [0.3554]]),\n",
       " tensor([[ 0.8969],\n",
       "         [ 0.4678],\n",
       "         [-0.0768],\n",
       "         [ 0.2708]]),\n",
       " tensor([[ 0.1805],\n",
       "         [ 0.8562],\n",
       "         [ 0.1429],\n",
       "         [-0.1136]]),\n",
       " tensor([[ 0.1414],\n",
       "         [ 0.9736],\n",
       "         [ 0.0205],\n",
       "         [-0.0984]]),\n",
       " tensor([[0.2952],\n",
       "         [0.4362],\n",
       "         [0.9340],\n",
       "         [0.0274]]),\n",
       " tensor([[0.0392],\n",
       "         [0.5494],\n",
       "         [1.2499],\n",
       "         [0.2418]]),\n",
       " tensor([[ 0.5239],\n",
       "         [ 0.9677],\n",
       "         [-0.4337],\n",
       "         [ 0.5814]]),\n",
       " tensor([[1.2802],\n",
       "         [0.2127],\n",
       "         [0.6671],\n",
       "         [0.0780]]),\n",
       " tensor([[0.8880],\n",
       "         [0.1786],\n",
       "         [0.1682],\n",
       "         [0.0879]]),\n",
       " tensor([[0.1694],\n",
       "         [0.0772],\n",
       "         [1.1131],\n",
       "         [0.0823]])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9535)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(torch.cat(labels).view(-1),torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation loops in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_step(model, data, optimizer):\n",
    "  optimizer.zero_grad()\n",
    "  for k, v in data.items():\n",
    "    data[k] = v.to(device)\n",
    "  loss = model(**data) \n",
    "  # loss = model(x=data[\"x\"], y=data[\"y\"])\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, schedular):\n",
    "  model.tran() # put model in training mode\n",
    "  total_loss = 0\n",
    "  for batch_idx, data in enumerate(data_loader):\n",
    "    loss = train_one_step(model, data, optimizer)\n",
    "    schedular.step() # step the learning rate scheduler\n",
    "    total_loss += loss # TODO: if average loss is required\n",
    "  return total_loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_step(model, data):\n",
    "  for k, v in data.items():\n",
    "    data[k] = v.to(device)\n",
    "  loss = model(**data)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, data_loader):\n",
    "  model.eval() # put model in evaluation mode\n",
    "  total_loss = 0\n",
    "  for batch_idx, data in enumerate(data_loader):\n",
    "    with torch.no_grad():\n",
    "      loss = validate_one_step(model, data)\n",
    "    total_loss += loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn \n",
    "docs: https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Containers:\n",
    "* Module \n",
    "* Sequential (keep the layer in sequential order, automatically pass one by one)\n",
    "* ModuleList (keep the layers in the list, you have to index them to use)\n",
    "* ModuleDict (keep the layers in the dictionary)\n",
    "\n",
    "Layers are:\n",
    "* Conv1d\n",
    "* Conv2d\n",
    "* MaxPool1d\n",
    "* MaxPool2d \n",
    "* AvgPool1d\n",
    "* AvgPool2d\n",
    "* BatchNorm1d\n",
    "* BatchNorm2d\n",
    "* LayerNorm\n",
    "* LSTM\n",
    "* GRU\n",
    "* Linear \n",
    "* Dropout\n",
    "* Embedding\n",
    "* Transformer\n",
    "* ReLU\n",
    "* Sigmoid\n",
    "* Flatten\n",
    "\n",
    "Activations are: \n",
    "* ReLU\n",
    "* LeakyReLU\n",
    "* Sigmoid\n",
    "* Tanh\n",
    "* Softmax\n",
    "\n",
    "Loss Functions: \n",
    "* MSELoss\n",
    "* CrossEntropyLoss \n",
    "* NLLLoss (log likelihood)\n",
    "* BCELoss \n",
    "* BCEWithLogitsLoss \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # super() is used to access the parent class\n",
    "    self.layer1 = nn.Linear(128, 32) # 128 input features, 32 output features\n",
    "    self.layer2 = nn.Linear(32, 16)\n",
    "    self.layer3 = nn.Linear(16, 1)\n",
    "  \n",
    "  def forward(self, featurs):\n",
    "    # (56, 128) # 56 is the batch size, 128 is the number of features\n",
    "    x = self.layer1(featurs)\n",
    "    # print(x.shape) # (56, 32) \n",
    "    x = self.layer2(x)\n",
    "    # print(x.shape) # (56, 16)\n",
    "    x = self.layer3(x)\n",
    "    # print(x.shape) # (56, 1)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "features = torch.rand((500, 128)) # 500 samples, 128 features\n",
    "output = model(features)\n",
    "print(output.shape) # (500, 1) -> for each sample one output as defined in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.to(device)\n",
    "model = Model()\n",
    "model.to(device=device)\n",
    "model(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of sequential \n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # super() is used to access the parent class\n",
    "    self.base = nn.Sequential( # all layers will be applied sequentially\n",
    "    nn.Linear(128, 32), # 128 input features, 32 output features\n",
    "    nn.Linear(32, 16),\n",
    "    nn.Linear(16, 1)\n",
    "    )\n",
    "\n",
    "  \n",
    "  def forward(self, featurs):\n",
    "    x = self.base(featurs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.to(device)\n",
    "model = Model()\n",
    "model.to(device=device)\n",
    "model(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as opt \n",
    "import torch.autograd as grad\n",
    "import torch.utils.data\n",
    "import torchvision \n",
    "import torchvision.datasets\n",
    "import torchvision.transforms \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_seed = 64 \n",
    "\n",
    "torch.manual_seed(random_seed) # seed for generating same random nos for the cpu\n",
    "\n",
    "torch.cuda.manual_seed(random_seed) # seed for generating same random nos for the gpu\n",
    "\n",
    "torch.backends.cudnn.deterministic = True  # forces to use deterministic algorithm in cuDNN by nvidia library, some operations in cuDNN can be non-deterministic which this setting prevents\n",
    "\n",
    "torch.backends.cudnn.benchmark = False # disable cuDNN's automatic optimization for finding the best algorithm, use same algo for consistency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
